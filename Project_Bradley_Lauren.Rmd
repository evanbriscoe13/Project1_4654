---
title: "Lauren_bradley_proj1"
author: "Lauren Bradley, Evan Briscoe"
date: "10/21/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(ggplot2)
```

# Main Goal: Create Loess Regression Function

```{r local_subset}
# Function that creates the windows 
create_subset <- function(obs, x, y, k){
  sub_df <- data.frame(x = x, y=y, dist = abs(obs-x))
  sub_df <- sub_df[order(sub_df$dist),]
  sub_df <- sub_df[1:k,]
  sub_df <- sub_df[order(sub_df$x),]
  return (sub_df)
}

```


```{r weight function}
# Function that creates the weights
triwts <- function(distances){
  #allocate weights vector
  wts <- double(length = length(distances))
  
  for (i in 1:length(distances)){
    if (abs(distances[i]) <= 1){
      wts[i] <- (1-abs(distances[i])**3)**3
    }
    else
      wts[i] <- 0
  }
  return (wts)
}
dist <- c(0.7866237, 0.3744029, 0.168412, 0.0000000, 0.6660479, 0.7498743, 1.0000000)
triwts(dist)
```

```{r}
# Your function will have the following inputs.
# 
# * x - a numeric input vector
# * y - a numeric response
#
# Note span and degree are shown with their default values. (Read about this in the description)
# * degree should be 1 or 2 only
# * span can be any value in interval (0, 1) non-inclusive.
#
# If show.plot = TRUE then you must show a plot of either the final fit
myloess <- function(x, y, span = 0.5, degree = 1, show.plot = TRUE){
  
  dat <- data.frame(x,y)
  # Your code goes here
  #N_total
  N_total <- length(x)
  #n_points
  n_points <- ceiling(length(y)*span)
  #Our fitted values vector
  y.fitted <- double(length = length(y))
  #past local subset
  past_loc_dat <- double(length = n_points)
  #Win_total
  Win_total = 0
  # Degree 2
  # index counter
  index = 1
  if(degree == 2){
    for (val in x){
      #Create current local subset vector
      loc_dat <- create_subset(val, x, y, n_points)
      #Compare to previous local subset
      # If previous local dataset is not equal to current
      if(!setequal(loc_dat$x, past_loc_dat)){
        Win_total = Win_total + 1
        past_loc_dat <- loc_dat$x
      }
      #calculate distance vector
      distances <- loc_dat$dist
      max.dist <- max(distances)
      #calculate scaled distances vector
      scale_dists <- distances/max.dist
      # call weight function to make vector
      wts <- triwts(scale_dists)
       #conduct weighted regression
      x_squared <- loc_dat$x^2
      fit <- lm(y~ x + x_squared, weights = wts, data = loc_dat)
      
      #calculate predicted value from regression fit and coefficients
      reg.value <- fit$coefficients[1] + fit$coefficients[2]*val +fit$coefficients[3]*val**2
      #Add to fitted values vector
      y.fitted[index] <- reg.value
      
      #increase index for next iteration
      index = index+1
    }
    
  }
  # Degree 1
  else{
    
    #Go through each point
    for (val in x){
      
      #Create current local subset vector
      loc_dat <- create_subset(val, x,y, n_points)
      #Compare to previous local subset
      # If previous local dataset is not equal to current
      if(!setequal(loc_dat$x, past_loc_dat)){
        Win_total = Win_total + 1
        past_loc_dat <- loc_dat$x
      }
      #calculate distance vector
      distances <- loc_dat$dist
      max.dist <- max(distances)
      #calculate scaled distances vector
      scale_dists <- distances/max.dist
      # call weight function to make vector
      wts <- triwts(scale_dists)
      #conduct weighted regression
      fit <- lm(y~ x, weights = wts, data = loc_dat)
      #calculate predicted value from regression fit and coefficients
      reg.value <- fit$coefficients[1] + fit$coefficients[2]*val
      #Add to fitted values vector
      y.fitted[index] <- reg.value
      
      #increase index for next iteration
      index = index+1
    }
    
  }
  SSE <- sum((y-y.fitted)**2)
  
  
  dat.fitted <- data.frame(x, y.fitted)
  loessplot <- ggplot(dat, aes(x = x, y = y)) + 
      theme_bw() + 
      geom_point() +
      geom_line(color='red', data = dat.fitted, aes(x = x, y = y.fitted))
      
  ls <- list('Span' = span, 'degree' = degree, 'N_total' = N_total, 'Win_total' = Win_total, 'n_points' = n_points, 'SSE' = SSE, 'loessplot' = loessplot)
  
  if (show.plot){
    return (ls)
  }
  else{
    return (ls[1:6])
  }
}
# Your function should return a named list containing the following:
# span: proportion of data used in each window (controls the bandwidth)
# degree: degree of polynomial
# N_total: total number of points in the data set
# Win_total: total number of windows
# n_points: number of points in each window in a vector
# SSE: Error Sum of Squares (Tells us how good of a fit we had).
# loessplot: An object containing the ggplot so that we can see the plot later. 
#  We want this even if show.plot = FALSE
#  Note: you are NOT allowed to simply use stat_smooth() or geom_smooth() to have it automatically do LOESS.
#  You should use geom_line() or similar to plot your final the LOESS curve.

# Make sure you can access the objects properly using the $ notation.
```

# Problem 1

```{r}
load("ozone.RData")
data("ozone")

ggplot(ozone, aes(x = temperature, y = ozone)) + theme_bw() + geom_point()

```

## 1. 

```{r}
temp_2 <- ozone$temperature^2
temp_3 <- ozone$temperature^3
temp_4 <- ozone$temperature^4
temp_5 <- ozone$temperature^5
temp_6 <- ozone$temperature^6

poly1 <- lm(ozone ~ temperature, data = ozone)
poly2 <- lm(ozone ~ temperature + temp_2, data = ozone)
poly3 <- lm(ozone ~ temperature + temp_2 + temp_3, data = ozone)
poly4 <- lm(ozone ~ temperature + temp_2 + temp_3 + temp_4, data = ozone)
poly5 <- lm(ozone ~ temperature + temp_2 + temp_3 + temp_4 + temp_5, data = ozone)
poly6 <- lm(ozone ~ temperature + temp_2 + temp_3 + temp_4 + temp_5 + temp_6, data = ozone)

summary(poly1)
summary(poly2)
summary(poly3)
summary(poly4)
summary(poly5)
summary(poly6)


```
By looking at the regression summaries, the polynomial fit that appears to work the best is degree = 4

## 2. Loess Regression Fits

```{r}
tab_content <- c()
for (i in seq(0.25,0.75,.05)){
  degree_1 <- myloess(ozone$temperature, ozone$ozone, span = i, degree = 1, show.plot = FALSE)
  degree_2 <- myloess(ozone$temperature, ozone$ozone, span = i, degree = 2, show.plot = FALSE)
  
  tab_content <- append(tab_content, degree_1$SSE)
  tab_content <- append(tab_content, degree_2$SSE)
  tab_content <- append(tab_content, i)
}

table <- matrix(tab_content, ncol = 3, byrow = TRUE)
colnames(table) <- c('Degree1SSE', 'Degree2SSE', 'Span')
table <- as.table(table)
table
```

The best fits for Degree 1 are spans 0.25, 0.30, 0.35.

The best fits for Degree 2 are spans 0.25, 0.30, 0.35.

```{r}
myloess(ozone$temperature, ozone$ozone, span = 0.25, degree = 1, show.plot = TRUE)$loessplot + labs(title = "Degree 1 Span 0.25")
myloess(ozone$temperature, ozone$ozone, span = 0.30, degree = 1, show.plot = TRUE)$loessplot + labs(title = "Degree 1 Span 0.30")
myloess(ozone$temperature, ozone$ozone, span = 0.35, degree = 1, show.plot = TRUE)$loessplot + labs(title = "Degree 1 Span 0.35")
myloess(ozone$temperature, ozone$ozone, span = 0.25, degree = 2, show.plot = TRUE)$loessplot + labs(title = "Degree 2 Span 0.25")
myloess(ozone$temperature, ozone$ozone, span = 0.30, degree = 2, show.plot = TRUE)$loessplot + labs(title = "Degree 2 Span 0.30")
myloess(ozone$temperature, ozone$ozone, span = 0.35, degree = 2, show.plot = TRUE)$loessplot + labs(title = "Degree 2 Span 0.35")

```
Yes, we feel that the data is over fit for degree 1 and 2's span of 0.25 because the line is super jagged with unnecessary curves.  The best span with a smoother curve is 0.35 for both degree 1 and 2.

## 3. Compare with loess()
```{r}
mod1_25 <- loess(ozone ~ temperature, data = ozone, span = 0.25, degree = 1)
mod1_30 <- loess(ozone ~ temperature, data = ozone, span = 0.30, degree = 1)
mod1_35 <- loess(ozone ~ temperature, data = ozone, span = 0.35, degree = 1)
mod2_25 <- loess(ozone ~ temperature, data = ozone, span = 0.25, degree = 2)
mod2_30 <- loess(ozone ~ temperature, data = ozone, span = 0.30, degree = 2)
mod2_35 <- loess(ozone ~ temperature, data = ozone, span = 0.35, degree = 2)

print("Degree 1 SSE")
sum(mod1_25$residuals^2)
sum(mod1_30$residuals^2)
sum(mod1_35$residuals^2)

print("Degree 2 SSE")
sum(mod2_25$residuals^2)
sum(mod2_30$residuals^2)
sum(mod2_35$residuals^2)
```

```{r}
ggplot(ozone, aes(x = temperature, y = ozone)) + geom_point() + geom_smooth(method = "loess") + labs(title = "Built-in Loess")
```

The graphs from problem 2 have more precise and frequent curves with the manual loess function while the graph in problem 3 with the geom_smooth() function has a smoother curve. 

# Problem 2

```{r}
library(MASS)
data("mcycle")

ggplot(mcycle, aes(x = times, y = accel)) + theme_bw() + geom_point()
```

## 1.

```{r}
tab_content <- c()
for (i in seq(0.25,0.75,.05)){
  degree_1 <- myloess(mcycle$times, mcycle$accel, span = i, degree = 1, show.plot = FALSE)
  degree_2 <- myloess(mcycle$times, mcycle$accel, span = i, degree = 2, show.plot = FALSE)
  
  tab_content <- append(tab_content, degree_1$SSE)
  tab_content <- append(tab_content, degree_2$SSE)
  tab_content <- append(tab_content, i)
}

table <- matrix(tab_content, ncol = 3, byrow = TRUE)
colnames(table) <- c('Degree1SSE', 'Degree2SSE', 'Span')
table <- as.table(table)
table
```

The best fits for Degree 1 are spans 0.25, 0.30, 0.35.

The best fits for Degree 2 are spans 0.25, 0.30, 0.35.

```{r}
myloess(mcycle$times, mcycle$accel, span = 0.25, degree = 1, show.plot = TRUE)$loessplot + labs(title = "Degree 1 Span 0.25")
myloess(mcycle$times, mcycle$accel, span = 0.30, degree = 1, show.plot = TRUE)$loessplot + labs(title = "Degree 1 Span 0.30")
myloess(mcycle$times, mcycle$accel, span = 0.35, degree = 1, show.plot = TRUE)$loessplot + labs(title = "Degree 1 Span 0.35")
myloess(mcycle$times, mcycle$accel, span = 0.25, degree = 2, show.plot = TRUE)$loessplot + labs(title = "Degree 2 Span 0.25")
myloess(mcycle$times, mcycle$accel, span = 0.30, degree = 2, show.plot = TRUE)$loessplot + labs(title = "Degree 2 Span 0.30")
myloess(mcycle$times, mcycle$accel, span = 0.35, degree = 2, show.plot = TRUE)$loessplot + labs(title = "Degree 2 Span 0.35")
```

The degree 2 models have a better fit than the degree 1 models. Degree 2 with a span of 0.30 and 0.35 have the best model fits. 

## 2. 

```{r}
mod1_25 <- loess(times ~ accel, data = mcycle, span = 0.25, degree = 1)
mod1_30 <- loess(times ~ accel, data = mcycle, span = 0.30, degree = 1)
mod1_35 <- loess(times ~ accel, data = mcycle, span = 0.35, degree = 1)
mod2_25 <- loess(times ~ accel, data = mcycle, span = 0.25, degree = 2)
mod2_30 <- loess(times ~ accel, data = mcycle, span = 0.30, degree = 2)
mod2_35 <- loess(times ~ accel, data = mcycle, span = 0.35, degree = 2)

print("Degree 1 SSE")
sum(mod1_25$residuals^2)
sum(mod1_30$residuals^2)
sum(mod1_35$residuals^2)

print("Degree 2 SSE")
sum(mod2_25$residuals^2)
sum(mod2_30$residuals^2)
sum(mod2_35$residuals^2)
```


```{r}
ggplot(mcycle, aes(x = times, y = accel)) + geom_point() + geom_smooth(method = "loess") + labs(title = "Built-in Loess")
```


The manual function we made is better than the built in function. 

```{r distance}
#calculate the distance between our current point x
# each training point in the testing data set (features only)
calculateDistances <- function(newData, training_features) {
  D <- dist(rbind(newData, training_features)) # Compute the L2 norm by default
  D <- as.matrix(D)[-1, 1]
  names(D) <- 1:nrow(training_features)
  return(D) # Returns a vector of the distances
}
tester <- data.frame(test1 = c(0,1,2), test2 = c(3,4,5), test3 = c(6,7,8))
tester2 <- c(1,2,3)
d <- calculateDistances(tester2, tester)
a <- c(7, 3, 4)
index = seq_along(a)
o <- order(a, decreasing = FALSE)
test <- cbind(a[o],index[o])
test
```

# Main Goal: kNN

```{r}
# Your function will have the following inputs similar to what you would find with the
#  knn() function
#
# * train - matrix or data frame of training set cases
# * test - matrix or data frame of test set cases.  
#     (A vector will be interpreted as a row vector for a single case.)
# * y_train - Either a numeric vector, or factor vector for the responses in the training set
# * y_test - Either a numeric vector, or factor vector for the responses in the testing set
# * k - number of neighbors considered, the default value is 3
#
# If weighted = TRUE, then your function must used the distance weighted kNN as described above,
#  otherwise it should do the default knn method.
library(class)

x <- factor(c(1,1,0,0))

mykNN <- function(train, test, y_train, y_test, k = 3, weighted = TRUE){
  
  # Your code goes here
  # Do kNN instead of weighted
  if (weighted == FALSE){
    dists <- calculateDistances(y_train, train)
    dists <- sort(dists)[1:k]
  }
    
    
    # If responses are factor vector (classification)
    if( is.factor(y_test)){
      
      
    }
    # Responses are number vector (Regression)
  else {
    # Go through each row (entry) of test 
    for (i in dim(test)[1]){
      # Get distances of test row with all training rows
      dists <- calculateDistances(test[i,], train)
      index <- seq_along(dists)
      o <- order(dists, decreasing = FALSE)
      # Grab k closest distances and indexes
      dists_k <- cbind(dists[o],index[o])[1:k,]

      weights <- 1/dists[,1]
      c <- weights/sum(weights)
      fitted_value = 0
      for (x in seq_along(index)){
        fitted_value <- fitted_value + (c[x]*y_train[x])
      }
      y_hat <- append(y_hat, fitted_value)
    }
    res_vec <- y_test - unlist(y_hat)
    SSE <- sum((y_test-unlist(y_hat))^2)
    
    return(y_hat, res_vec, SSE, k)
  }
  
  return("list of objects seen below")
}

# If you are doing classification, then your function must return:
#  * A factor vector (yhat) for the predicted categories for the testing data
#  * The accuracy of the classification
#  * The error rate = 1 - accuracy
#  * A confusion matrix
#  * The value of k used

# If you are doing regression, then your function must return:
#  * A numeric vector (yhat) for the predicted responses for the testing data
#  * The residual vector
#  * The SSE
#  * The value of k used
```

